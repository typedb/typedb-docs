= TypeDB Cloud Self-hosted
:page-aliases: typedb::managing/self-hosted-deployment.adoc, typedb::admin/enterprise-deployment.adoc
:experimental:

This page is an installation guide for a self-hosted deployment of TypeDB Cloud.
You can get a license for it from our sales team: contact us via
mailto:cloud@typedb.com[e-mail,window=_blank] or
https://typedb.com/deploy?dialog=contact[contact form,window=_blank].

[IMPORTANT]
====
TypeDB Cloud is available as a fully managed cloud service with no installation required at
https://cloud.typedb.com/[cloud.typedb.com].
====

== System Requirements

TypeDB Cloud runs on macOS, Linux, and Windows.
The only requirement is Java v.11+ (http://openjdk.java.net/install/[OpenJDK] or
https://www.oracle.com/java/technologies/downloads/#java11[Oracle Java]).

== Download and Install

TypeDB Cloud is distributed and installed separately from TypeDB Core.

Request access to the TypeDB Cloud distributive repositories from Vaticle.
You can do that via technical support, using the contact details from your contract, or through our
https://typedb.com/discord[Discord,window=_blank] server.

Then you can install it with <<_using_docker,Docker>> or manual
<<_manual_download_and_installation,download and installation>>.

You can deploy a cluster of TypeDB Cloud servers
<<_deploying_manually,manually>> or via <<_deploying_with_kubernetes,Kubernetes>>.

If you don't have a license yet, you can try our https://cloud.typedb.com/[TypeDB Cloud] service or contact our
mailto:cloud@typedb.com[sales team].

[#_using_docker]
=== Docker

TypeDB Cloud Docker image is stored in a private repository.
Make sure to use `docker login` first, to get correct authentication.

To pull the TypeDB Cloud Docker image, run:

[source,console]
----
$ docker pull vaticle/typedb-cloud:latest
----

Use `docker run` to create a new container with the downloaded image.
By default, a TypeDB Cloud server is expected to be running on port `1729`.
To ensure that data is preserved even when the container is killed or restarted, use a Docker volume:

[source,console]
----
$ docker run --name typedb -d -v $(pwd)/db/:/opt/ -p 1729:1729 vaticle/typedb-cloud:latest
----

==== Start and Stop TypeDB Cloud in Docker

To start the Docker container:

[source,console]
----
$ docker start typedb
----

To check the containers running:

[source,console]
----
$ docker ps
----

To stop the Docker container:

[source,console]
----
$ docker stop typedb
----

[#_manual_download_and_installation]
=== Manual installation

Make sure to have access to the main repository: https://repo.typedb.com.

Download the https://cloudsmith.io/~typedb/repos/private-release/packages/?q=cloud&sort=-version[latest release],
unzip it in a location on your machine that is easily accessible via terminal.

If TypeDB doesn't have a distribution you need, please open an issue
https://github.com/vaticle/typedb/issues[on GitHub].

==== Start and Stop TypeDB Cloud manually

To start TypeDB Cloud manually:

1. Navigate into the directory with unpacked files of TypeDB Cloud.
2. Run:
+
[source,console]
----
$ ./typedb server
----

Now TypeDB Cloud should show a welcome screen with its version, address, and bootup time.

To stop TypeDB Cloud:

Close the terminal or press kbd:[Ctrl+C].

== Connecting

To check whether TypeDB Cloud is working and interact with it, you can connect to it with any
xref:drivers:ROOT:overview.adoc[TypeDB Client].

You can use xref:manual:ROOT:console.adoc[TypeDB Console] from your TypeDB Cloud directory:

[source,console]
----
$ ./typedb console --cloud 127.0.0.1:1729 --username admin --password
----

To run TypeDB Console from a Docker container, run:

[source,console]
----
$ docker exec -ti typedb-cloud bash -c '/opt/typedb-cloud-all-linux-x86_64/typedb console --cloud 127.0.0.1:1729 --username admin --password'
----

[#_deploying_manually]
== Deploying manually

While it's possible to run TypeDB Cloud in a single-server mode, a highly available and fault-tolerant
production-grade setup includes setting up multiple servers to connect and form a cluster.
At any given point in time, one of those servers acts as a leader, and the others are followers.
Increasing the number of servers increases the
cluster's tolerance to failure: to tolerate N servers failing, a cluster needs to consist of `2N + 1` servers.
This section describes how you can set up a 3-server cluster (in this case,
one server can fail with no data loss).

Each TypeDB Cloud server in a cluster binds to three ports:
a client port that TypeDB drivers connect to (`1729` by default) and two server ports
(`1730` and `1731`) for server-to-server communication.

For this tutorial, it's assumed that all three servers are on the same virtual network, have the relevant ports open,
with no firewall interference, and the servers have IP addresses `10.0.0.1`, `10.0.0.2` and `10.0.0.3` respectively.

[NOTE]
====
If you're using a single machine to host all nodes,
it may be easier to use `localhost` or `127.0.0.1` address, but prefix the port with the node number; this way the
ports `1729`, `1730`, `1731` would turn into:

* `11729`, `11730`, `11731`;
* `21729`, `21730`, `21731`;
* `31729`, `31730`, `31731`.
====

=== Starting

TypeDB servers working in a cluster shall be configured specifically to know all servers in the cluster (peers).
This could be done through `peers` key in the server config, or with command-line arguments when starting the server.
Command-line arguments have priority over config file.

See below an example of how 3-server TypeDB Cloud would be started on three separate machines to be in a cluster.

.Server #1
====
The first machine with the IP address of `10.0.0.1`.

To run TypeDB server #1:

[source,console]
----
$ ./typedb server \
    --server.address=10.0.0.1:1729 \
    --server.internal-address.zeromq=10.0.0.1:1730 \
    --server.internal-address.grpc=10.0.0.1:1731 \
    --server.peers.peer-1.address=10.0.0.1:1729 \
    --server.peers.peer-1.internal-address.zeromq=10.0.0.1:1730 \
    --server.peers.peer-1.internal-address.grpc=10.0.0.1:1731 \
    --server.peers.peer-2.address=10.0.0.2:1729 \
    --server.peers.peer-2.internal-address.zeromq=10.0.0.2:1730 \
    --server.peers.peer-2.internal-address.grpc=10.0.0.2:1731 \
    --server.peers.peer-3.address=10.0.0.3:1729 \
    --server.peers.peer-3.internal-address.zeromq=10.0.0.3:1730 \
    --server.peers.peer-3.internal-address.grpc=10.0.0.3:1731
----
====

.Server #2
====
The first machine with the IP address of `10.0.0.2`.

To run TypeDB server #2:

[source,console]
----
$ ./typedb server \
    --server.address=10.0.0.2:1729 \
    --server.internal-address.zeromq=10.0.0.2:1730 \
    --server.internal-address.grpc=10.0.0.2:1731 \
    --server.peers.peer-1.address=10.0.0.1:1729 \
    --server.peers.peer-1.internal-address.zeromq=10.0.0.1:1730 \
    --server.peers.peer-1.internal-address.grpc=10.0.0.1:1731 \
    --server.peers.peer-2.address=10.0.0.2:1729 \
    --server.peers.peer-2.internal-address.zeromq=10.0.0.2:1730 \
    --server.peers.peer-2.internal-address.grpc=10.0.0.2:1731 \
    --server.peers.peer-3.address=10.0.0.3:1729 \
    --server.peers.peer-3.internal-address.zeromq=10.0.0.3:1730 \
    --server.peers.peer-3.internal-address.grpc=10.0.0.3:1731
----
====

.Server #3
====
The first machine with the IP address of `10.0.0.3`.

To run TypeDB server #3:

[source,console]
----
$ ./typedb server \
    --server.address=10.0.0.3:1729 \
    --server.internal-address.zeromq=10.0.0.3:1730 \
    --server.internal-address.grpc=10.0.0.3:1731 \
    --server.peers.peer-1.address=10.0.0.1:1729 \
    --server.peers.peer-1.internal-address.zeromq=10.0.0.1:1730 \
    --server.peers.peer-1.internal-address.grpc=10.0.0.1:1731 \
    --server.peers.peer-2.address=10.0.0.2:1729 \
    --server.peers.peer-2.internal-address.zeromq=10.0.0.2:1730 \
    --server.peers.peer-2.internal-address.grpc=10.0.0.2:1731 \
    --server.peers.peer-3.address=10.0.0.3:1729 \
    --server.peers.peer-3.internal-address.zeromq=10.0.0.3:1730 \
    --server.peers.peer-3.internal-address.grpc=10.0.0.3:1731
----
====

The above example assumes
the application (TypeDB Client) accessing TypeDB Cloud resides on the same private network as the cluster.

If this is *not* the case,
TypeDB Cloud also supports using different IP addresses for client and server communication.

.Example of using separate network for client connection
====

The relevant external hostname should be passed as arguments using the `--server.address` and
`--server.peers` flags as below.

[source,console]
----
$ ./typedb server \
    --server.address=external-host-1:1729 \
    --server.internal-address.zeromq=10.0.0.1:1730 \
    --server.internal-address.grpc=10.0.0.1:1731 \
    --server.peers.peer-1.address=external-host-1:1729 \
    --server.peers.peer-1.internal-address.zeromq=10.0.0.1:1730 \
    --server.peers.peer-1.internal-address.grpc=10.0.0.1:1731 \
    --server.peers.peer-2.address=external-host-2:1729 \
    --server.peers.peer-2.internal-address.zeromq=10.0.0.2:1730 \
    --server.peers.peer-2.internal-address.grpc=10.0.0.2:1731 \
    --server.peers.peer-3.address=external-host-3:1729 \
    --server.peers.peer-3.internal-address.zeromq=10.0.0.3:1730 \
    --server.peers.peer-3.internal-address.grpc=10.0.0.3:1731
----

And so on for servers #2 and #3.

In this case, port `1729` would need to be open to public and clients would use the `external-host-1`, `external-host-2`
and `external-host-3` hostnames to communicate with TypeDB Cloud; inter-server communication would be done over a
private network using ports `1730` and `1731`.
====

=== Stopping

Stopping TypeDB Cloud is done the same way as on a single server:
to stop TypeDB Cloud, close the terminal or press kbd:[Ctrl+C].
All nodes must be shut down independently in the same way.

[#_deploying_with_kubernetes]
== Kubernetes

To deploy a TypeDB Cloud cluster with Kubernetes, we can use https://helm.sh/[Helm] package manager.

include::manual::partial$kubernetes.adoc[leveloffset=+1]
